# Identify nomal clusters and anomalous clusters with nomal data
# Input 'data' is initial data

import numpy as np
import multiprocessing
import os
# from utils.class_row import nomal_class_data

# Helper function for parallel processing of a single cluster
def _process_single_cluster_label(cluster_id, data_features_for_clustering, clusters_assigned, known_normal_samples_features_to_compare, threshold):
    cluster_mask = (clusters_assigned == cluster_id)
    
    if not np.any(cluster_mask):
        return cluster_id, None, -1 # cluster_id, mask, label (-1 indicates no label assigned / empty cluster)

    current_cluster_features = data_features_for_clustering[cluster_mask]

    if current_cluster_features.size == 0 or (known_normal_samples_features_to_compare is not None and known_normal_samples_features_to_compare.size == 0):
        num_normal_in_cluster = 0
    elif known_normal_samples_features_to_compare is None: # Should not happen if fallback logic for global_known_normal_samples_pca is robust
        num_normal_in_cluster = 0
        print(f"[WARN CNI Helper] known_normal_samples_features_to_compare is None for cluster {cluster_id}")
    else:
        try:
            comparison_matrix = (current_cluster_features[:, None, :] == known_normal_samples_features_to_compare[None, :, :])
            all_features_match = np.all(comparison_matrix, axis=2)
            any_known_normal_matches = np.any(all_features_match, axis=1)
            num_normal_in_cluster = np.sum(any_known_normal_matches)
        except ValueError as e:
            print(f"[Error CNI Helper comparing cluster {cluster_id}] shape mismatch or other ValueError: {e}")
            print(f"  Cluster features shape: {current_cluster_features.shape}, Known normal features shape: {known_normal_samples_features_to_compare.shape}")
            num_normal_in_cluster = 0 # Treat as anomalous on error
        except MemoryError as me:
            print(f"[Error CNI Helper comparing cluster {cluster_id}] MemoryError: {me}")
            num_normal_in_cluster = 0 # Treat as anomalous on error
    
    normal_ratio = num_normal_in_cluster / len(current_cluster_features) if len(current_cluster_features) > 0 else 0
    label_for_final_output = 0 if normal_ratio >= threshold else 1
    
    return cluster_id, cluster_mask, label_for_final_output

# Change function signature:
# data_features_for_clustering: NumPy array of features used for clustering (e.g. X_reduced, shape (N, num_pca_features))
# original_labels_aligned: Original labels for each row in data_features_for_clustering (0 or 1, shape (N,))
# clusters_assigned: Cluster IDs assigned to each row in data_features_for_clustering (shape (N,))
# num_total_clusters: Total number of clusters generated by the clustering algorithm
# global_known_normal_samples_pca: Pre-sampled (e.g., 80% of all known normals) PCA features of known normal samples from the entire dataset.
def clustering_nomal_identify(data_features_for_clustering, original_labels_aligned, clusters_assigned, num_total_clusters, global_known_normal_samples_pca=None, threshold_value=0.3):
    
    print(f"\n[DEBUG CNI] Received 'data_features_for_clustering' - Shape: {data_features_for_clustering.shape}")
    if data_features_for_clustering.ndim == 2 and data_features_for_clustering.shape[0] > 0:
        print(f"[DEBUG CNI]   NumPy array - First 5 cols of first row: {data_features_for_clustering[0, :min(5, data_features_for_clustering.shape[1])] if data_features_for_clustering.shape[1] > 0 else '0 cols'}")
    print(f"[DEBUG CNI] Received 'original_labels_aligned' - Shape: {original_labels_aligned.shape}, Unique values: {np.unique(original_labels_aligned, return_counts=True)}")
    print(f"[DEBUG CNI] Received 'clusters_assigned' - Shape: {clusters_assigned.shape}, Unique values: {np.unique(clusters_assigned, return_counts=True)}")
    print(f"[DEBUG CNI] Received 'num_total_clusters': {num_total_clusters}")
    if global_known_normal_samples_pca is not None:
        print(f"[DEBUG CNI] Received 'global_known_normal_samples_pca' - Shape: {global_known_normal_samples_pca.shape if global_known_normal_samples_pca is not None else 'None'}")
    else:
        # Fallback or error if global_known_normal_samples_pca is not provided,
        # or implement the old way of deriving it from original_labels_aligned if that's desired as a fallback.
        # For now, we assume it will be provided when this modified function is used in the new 청크화 context.
        # If used in the old context (whole data), the caller needs to prepare and pass it.
        print(f"[WARN CNI] 'global_known_normal_samples_pca' not provided. This function now expects it.")
        # As a temporary measure for calls that haven't been updated, try to use the old method
        # THIS IS A TEMPORARY FALLBACK AND SHOULD BE REMOVED ONCE ALL CALLERS ARE UPDATED
        if original_labels_aligned is not None and data_features_for_clustering.shape[0] == original_labels_aligned.shape[0]:
            print("[WARN CNI] Using fallback to derive known_normal_samples_features from original_labels_aligned.")
            temp_known_normal_samples = data_features_for_clustering[original_labels_aligned == 0]
            num_temp_known_normal = temp_known_normal_samples.shape[0]
            if num_temp_known_normal > 1:
                sample_size = int(num_temp_known_normal * 0.95)
                if sample_size == 0 and num_temp_known_normal > 0: sample_size = 1
                # Ensure sample_size does not exceed population
                if sample_size > num_temp_known_normal : sample_size = num_temp_known_normal

                if sample_size > 0:
                    random_indices = np.random.choice(num_temp_known_normal, size=sample_size, replace=False)
                    global_known_normal_samples_pca = temp_known_normal_samples[random_indices]
                    print(f"[DEBUG CNI Fallback] Derived known_normal_samples_features, shape: {global_known_normal_samples_pca.shape}")
                else: # if sample_size is 0
                    global_known_normal_samples_pca = np.array([])
                    print(f"[DEBUG CNI Fallback] Sample size became 0, derived empty known_normal_samples_features.")

            elif num_temp_known_normal == 1:
                global_known_normal_samples_pca = temp_known_normal_samples
                print(f"[DEBUG CNI Fallback] Derived known_normal_samples_features (1 sample), shape: {global_known_normal_samples_pca.shape}")
            else:
                global_known_normal_samples_pca = np.array([]) # Empty
                print(f"[DEBUG CNI Fallback] No known normal samples to derive from original_labels_aligned.")
        else:
            # If fallback also not possible
            raise ValueError("global_known_normal_samples_pca must be provided, or original_labels_aligned and data_features_for_clustering for fallback.")


    # The global_known_normal_samples_pca is already sampled (e.g., 80%) and in PCA space.
    # So, we use it directly.
    known_normal_samples_features_to_compare = global_known_normal_samples_pca

    if known_normal_samples_features_to_compare is not None and known_normal_samples_features_to_compare.ndim == 2 and known_normal_samples_features_to_compare.shape[0] > 0:
         print(f"[DEBUG CNI] Using 'known_normal_samples_features_to_compare' (from global_known_normal_samples_pca) - Shape: {known_normal_samples_features_to_compare.shape}")
         if known_normal_samples_features_to_compare.shape[0] > 0:
            print(f"[DEBUG CNI]   NumPy array - First 5 cols of first row: {known_normal_samples_features_to_compare[0, :min(5, known_normal_samples_features_to_compare.shape[1])] if known_normal_samples_features_to_compare.shape[1] > 0 else '0 cols'}")
    else:
        print(f"[DEBUG CNI] 'known_normal_samples_features_to_compare' is empty or not valid. All clusters will likely be marked anomalous.")
        # Create an empty array with correct number of columns if possible, to avoid errors in comparison loop, though it won't match anything.
        # The number of columns should match data_features_for_clustering.
        if data_features_for_clustering.ndim == 2 and data_features_for_clustering.shape[1] > 0:
            known_normal_samples_features_to_compare = np.empty((0, data_features_for_clustering.shape[1]))
        else: # Cannot determine number of features, this will likely lead to an error later
            known_normal_samples_features_to_compare = np.array([])


    # final_labels will have the same length as data_features_for_clustering and clusters_assigned
    final_labels = np.zeros(len(data_features_for_clustering), dtype=int) 
    # threshold = 0.3 # This will be varied for experiments # Original line commented out
    # Using the passed threshold_value instead of the hardcoded one.
    # The actual optimization loop will be in Data_Labeling.py which calls this function.

    # Prepare arguments for parallel processing
    # known_normal_samples_features_to_compare might be an empty array, helper must handle it.
    tasks = [(cid, data_features_for_clustering, clusters_assigned, known_normal_samples_features_to_compare, threshold_value) for cid in range(num_total_clusters)] # Pass threshold_value

    # Determine number of processes
    # Use half of the CPU cores, but at least 1. Ensure it's an int.
    # num_processes = max(1, int(os.cpu_count() / 2)) if os.cpu_count() else 1 # os.cpu_count() can be None
    num_processes = os.cpu_count()
    if num_processes is None: # Fallback if os.cpu_count() returns None
        num_processes = 4 # A sensible default
    else:
        num_processes = max(1, int(num_processes / 2))


    print(f"[INFO CNI] Starting parallel processing for {num_total_clusters} clusters using {num_processes} processes.")
    
    try:
        with multiprocessing.Pool(processes=num_processes) as pool:
            results = pool.starmap(_process_single_cluster_label, tasks)
        
        for cluster_id, cluster_mask, label_for_final_output in results:
            if cluster_mask is not None and label_for_final_output != -1 : # Check if the cluster was processed
                final_labels[cluster_mask] = label_for_final_output
            elif label_for_final_output == -1: # Empty cluster
                # print(f"[INFO CNI] Cluster {cluster_id} was empty or skipped by helper.")
                pass


    except Exception as e:
        print(f"[ERROR CNI] Parallel processing failed: {e}. Falling back to sequential processing.")
        # Sequential fallback
        for cluster_id in range(num_total_clusters):
            # This is a simplified call for the sequential part.
            # In a real scenario, ensure _process_single_cluster_label is robust
            # or replicate the original loop logic here.
            # For now, reusing the helper, but direct original loop logic might be safer for fallback.
            _ , cluster_mask_seq, label_for_final_output_seq = _process_single_cluster_label(
                cluster_id, data_features_for_clustering, clusters_assigned, 
                known_normal_samples_features_to_compare, threshold_value # Pass threshold_value
            )
            if cluster_mask_seq is not None and label_for_final_output_seq != -1:
                final_labels[cluster_mask_seq] = label_for_final_output_seq
            # else:
                # print(f"[INFO CNI Seq] Cluster {cluster_id} was empty or skipped by helper during fallback.")

    return final_labels