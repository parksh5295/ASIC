import argparse
import time
import pandas as pd
import json
import os
from datetime import datetime

# Import existing modules from the project
from Rebuild_Method.FalsePositive_Check import apply_signatures_to_dataset, evaluate_false_positives, summarize_fp_results
from Dataset_Choose_Rule.dtype_optimize import load_csv_safely
from Dataset_Choose_Rule.save_signature_validation import save_validation_results

def ensure_directory_exists(filepath):
    """Ensures the directory for a given file path exists."""
    directory = os.path.dirname(filepath)
    if directory and not os.path.exists(directory):
        print(f"Creating directory: {directory}")
        os.makedirs(directory)

def load_signatures(filepath):
    """Loads signatures from a CSV file."""
    print(f"Loading signatures from {filepath}...")
    signatures_df = pd.read_csv(filepath)
    # Convert rule_dict from string back to dictionary
    signatures_df['rule_dict'] = signatures_df['rule_dict'].apply(eval)
    return signatures_df.to_dict('records')

def run_pipeline(args):
    """Main pipeline for signature generation, validation, and filtering."""
    
    total_start_time = time.time()
    
    # Define file paths based on arguments
    base_path = f"../Dataset_Paral/signature/{args.file_type}/"
    output_dir = f"./Output/{args.file_type}/"
    ensure_directory_exists(output_dir)

    # Path to the initial candidate signatures generated by the association rule module
    candidate_signatures_path = f"{base_path}{args.file_type}_{args.association}_{args.file_number}_{args.association_metric}_signature_train_ea{args.signature_ea}.csv"
    
    # Path to the benign dataset for false positive validation
    benign_data_path = args.benign_data_path # e.g., './Dataset/normal_traffic.csv'

    # Output paths
    final_signatures_path = f"{output_dir}final_signatures.csv"
    fp_report_path = f"{output_dir}fp_validation_report.json"

    # 1. Load candidate signatures
    print("-" * 50)
    print("Step 1: Loading candidate signatures...")
    if not os.path.exists(candidate_signatures_path):
        print(f"ERROR: Candidate signatures file not found at {candidate_signatures_path}")
        return
    candidate_signatures = load_signatures(candidate_signatures_path)
    print(f"Loaded {len(candidate_signatures)} candidate signatures.")

    # 2. Load benign dataset for FP check
    print("-" * 50)
    print("Step 2: Loading benign dataset for false positive validation...")
    if not os.path.exists(benign_data_path):
        print(f"ERROR: Benign dataset not found at {benign_data_path}")
        return
    # Assuming the benign dataset is pre-processed and compatible with signatures
    benign_df = pd.read_csv(benign_data_path)
    print(f"Loaded benign dataset with {len(benign_df)} rows.")

    # 3. Apply signatures to benign data to generate alerts
    print("-" * 50)
    print("Step 3: Applying signatures to benign data to generate alerts...")
    start_time = time.time()
    # Create a map for quick lookup by ID
    signatures_map = {sig['id']: sig for sig in candidate_signatures}
    alerts_on_benign = apply_signatures_to_dataset(benign_df, candidate_signatures)
    print(f"Generated {len(alerts_on_benign)} alerts from {len(alerts_on_benign['signature_id'].unique())} unique signatures on benign data.")
    print(f"Time taken: {time.time() - start_time:.2f} seconds.")

    # 4. Evaluate for false positives
    print("-" * 50)
    print("Step 4: Evaluating alerts for false positive characteristics (NRA, HAF, UFP)...")
    start_time = time.time()
    fp_eval_results = evaluate_false_positives(
        alerts_df=alerts_on_benign,
        current_signatures_map=signatures_map,
        attack_free_df=benign_df,
        t0_nra=args.fp_t0_nra,
        n0_nra=args.fp_n0_nra,
        lambda_haf=args.fp_lambda_haf,
        lambda_ufp=args.fp_lambda_ufp,
        combine_method=args.fp_combine_method,
        belief_threshold=args.fp_belief_threshold
    )
    print(f"Time taken: {time.time() - start_time:.2f} seconds.")

    # 5. Summarize results and filter signatures
    print("-" * 50)
    print("Step 5: Summarizing results and filtering signatures...")
    fp_summary = summarize_fp_results(fp_eval_results)
    
    high_fp_signatures = fp_summary['High FP Signatures']
    good_signatures_ids = set(signatures_map.keys()) - set(high_fp_signatures.keys())

    final_signatures = [sig for sig in candidate_signatures if sig['id'] in good_signatures_ids]
    
    print(f"Initial candidate signatures: {len(candidate_signatures)}")
    print(f"Identified as high FP: {len(high_fp_signatures)}")
    print(f"Final validated signatures: {len(final_signatures)}")

    # 6. Save results
    print("-" * 50)
    print("Step 6: Saving final signatures and FP report...")
    
    # Save final, validated signatures
    pd.DataFrame(final_signatures).to_csv(final_signatures_path, index=False)
    print(f"Validated signatures saved to {final_signatures_path}")

    # Save the detailed FP report
    with open(fp_report_path, 'w') as f:
        json.dump(fp_summary, f, indent=4)
    print(f"False positive report saved to {fp_report_path}")

    print("-" * 50)
    total_time = time.time() - total_start_time
    print(f"Pipeline finished in {total_time:.2f} seconds.")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Automated Signature Generation and Validation Pipeline')

    # Arguments for file paths and identifiers
    parser.add_argument('--file_type', type=str, default="MiraiBotnet", help='Type of the dataset (e.g., MiraiBotnet, DARPA98)')
    parser.add_argument('--file_number', type=int, default=1, help='File number identifier')
    parser.add_argument('--benign_data_path', type=str, required=True, help='Path to the pre-processed benign dataset CSV for FP validation')
    
    # Arguments from original scripts for loading candidate signatures
    parser.add_argument('--association', type=str, default="apriori", help='Association rule method used')
    parser.add_argument('--association_metric', type=str, default='confidence', help='Metric used for association rules')
    parser.add_argument('--signature_ea', type=int, default=15, help='Number of signatures parameter')

    # Arguments for FP detection logic from Validate_Signature.py
    parser.add_argument('--fp_belief_threshold', type=float, default=0.8, help='Threshold for FP belief score to classify a signature as FP')
    parser.add_argument('--fp_t0_nra', type=int, default=60, help='Time window (seconds) for NRA calculation')
    parser.add_argument('--fp_n0_nra', type=int, default=20, help='Normalization factor for NRA calculation')
    parser.add_argument('--fp_lambda_haf', type=float, default=100.0, help='Lambda parameter for HAF score calculation')
    parser.add_argument('--fp_lambda_ufp', type=float, default=10.0, help='Lambda parameter for UFP score calculation')
    parser.add_argument('--fp_combine_method', type=str, default='max', choices=['max', 'weighted_sum'], help='Method to combine NRA, HAF, UFP scores')

    args = parser.parse_args()

    # --- Conditional FP Parameter Override (similar to Validate_Signature.py) ---
    if args.file_type in ["DARPA98", "DARPA"]:
        print("INFO: File type is DARPA. Applying specific stricter FP parameters for validation.")
        if args.fp_belief_threshold == 0.8:
             args.fp_belief_threshold = 0.95
        if args.fp_t0_nra == 60:
             args.fp_t0_nra = 180
        if args.fp_n0_nra == 20:
             args.fp_n0_nra = 100
        if args.fp_lambda_haf == 100.0:
             args.fp_lambda_haf = 25.0
        if args.fp_lambda_ufp == 10.0:
             args.fp_lambda_ufp = 2.5
    
    run_pipeline(args) 